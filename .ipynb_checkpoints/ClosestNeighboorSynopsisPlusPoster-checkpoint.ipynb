{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function ShowkNN returns the closest neighbors using a k-NN algorithm from 600 concatenated features of image and synopsis.\n",
    "\n",
    "### The image poster features are first reduced to 300 features using a t-SVD algorithm. The features for both image and synopsis are normalized, and then concatenated before using them with a k-NN algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import string\n",
    "import re\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from keras.models import Model\n",
    "from quiver_engine.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from VGG16_PretrainedV1 import VGG16\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from sqlalchemy import Column, Integer, MetaData, Table\n",
    "import psycopg2\n",
    "from scipy import spatial\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Open and resize Image function \n",
    "def resize(im_ori):\n",
    "    img = Image.open(im_ori)\n",
    "    if img.mode == 'L' or img.mode == 'RGBA':\n",
    "            img = img.convert('RGB')\n",
    "    img = img.resize((224, 224), Image.ANTIALIAS)\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    return x;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Function show_knn which returns an array of indices corresponding to the nearest neighbor movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Input of ShowkNN function: \n",
    "    - Oview: User's snynopsis input\n",
    "    - ImOri: User's Image input\n",
    "    - Genr: User's genre filter input\n",
    "    - Country: User's country filter input\n",
    "    - DateRange1: User's minimum date\n",
    "    - DateRange1: User's maximum date\n",
    "    '''\n",
    "def show_knn(oview, im_ori, genr, country, date_range1, date_range2):\n",
    "    oview=str(oview)\n",
    "    im_ori=str(im_ori)\n",
    "    genr=str(genr)\n",
    "    country=str(country)\n",
    "    date_range1=int(date_range1)\n",
    "    date_range2=int(date_range2)\n",
    "\n",
    "    ##### Load VGG16 base model with second to last layer\n",
    "    base_model = VGG16(weights='imagenet')\n",
    "    model2 = Model(input=base_model.input, output=base_model.get_layer('fc2').output)\n",
    "    \n",
    "    ##### Load and resize input image\n",
    "    resize(im_ori)\n",
    "    \n",
    "    ##### Get the 4096 features from second to last layer fc2 from input image\n",
    "    fc2_features = model2.predict(x)\n",
    "\n",
    "    ##### Load Google's pre-trained Word2Vec model.\n",
    "    model1 = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "    vectors=list()\n",
    "    \n",
    "    ##### Convert Overview to array of string\n",
    "    sentence = \"%s\" % oview\n",
    "    sentence = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    \n",
    "    ##### Remove stop words\n",
    "    sentence_filtered = [word for word in sentence if word not in stopwords.words('english')]\n",
    "    \n",
    "    ##### Loop over words and get their 300 features each\n",
    "    for w in sentence_filtered:\n",
    "        try:\n",
    "            vectors.append(model1[w]) \n",
    "        except:\n",
    "            continue    \n",
    "    ##### Average the features over the whole synopsis\n",
    "    mean_vec=list()\n",
    "    mean_vec=[sum(x)/len(vectors) for x in zip(*vectors)]\n",
    "    word2vec_features = mean_vec\n",
    "    \n",
    "    ##### Convert word2vec_features to numpy array for future concatenation\n",
    "    word2vec_features=np.asarray(word2vec_features)\n",
    "\n",
    "    ##### Connection to DB and bind the connection to MetaData()   \n",
    "    dbname = 'DBName'\n",
    "    username = 'postgres'\n",
    "    engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "    metadata = MetaData(engine)\n",
    "    metadata.reflect(bind=engine)\n",
    "\n",
    "    ##### Create pandas df from sql database table #######\n",
    "    with engine.connect() as conn:\n",
    "        select_statement = metadata.tables['FilmTable'].select()\n",
    "        pdfilm_table_from_sqlnew = pd.read_sql_query(select_statement,conn)\n",
    "        path_image_dl=\"http://image.tmdb.org/t/p/original/\"\n",
    "    \n",
    "    ##### Create arrays to use for storage\n",
    "    prod_countries=list()\n",
    "    genre_table=list()\n",
    "    movie_title_table=list()\n",
    "    posterpath_table=list()\n",
    "    fc2array=list()\n",
    "    genres_array=list()\n",
    "    word2vecarray=list()\n",
    "    date=list()\n",
    "\n",
    "    increment=0\n",
    "    ##### Loop over fc2 in pandas df\n",
    "    for fc2str in pdfilm_table_from_sqlnew.fc2[(pdfilm_table_from_sqlnew.fc2.str.\\\n",
    "                                                contains(\"None\")) == False]:\n",
    "        ##### Conditions on genre\n",
    "        genres_array=pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str, 'genres'].item()\n",
    "        if(genr!=\"All\"):\n",
    "            genre_filter1bool=False\n",
    "            genre_filter1=genr\n",
    "            genre_filter2bool=False\n",
    "            for i in range(0,len(genres_array)):\n",
    "                if genres_array[i] == '%s' % genre_filter1:\n",
    "                    genre_filter1bool=True\n",
    "            if(genre_filter1bool == False and genre_filter2bool==False):\n",
    "                continue\n",
    "\n",
    "        ##### Conditions on country\n",
    "        country_array=pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str, 'production_countries_iso_3166_1'].item()\n",
    "        if(country!=\"All\"):\n",
    "            country_filterbool=False\n",
    "            country_filter=country\n",
    "            for i in range(0,len(country_array)):\n",
    "                if country_array[i] == '%s' % country_filter:\n",
    "                    country_filterbool=True\n",
    "            if(country_filterbool == False):\n",
    "                continue\n",
    "                \n",
    "        ##### Conditions on date\n",
    "        date=\"%s\" % pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str, 'release_date'].item()\n",
    "        date=re.findall(r\"[\\w']+\", date)\n",
    "        date=int(date[0])\n",
    "        if(date_filter!=\"All\"):\n",
    "            date_filterbool=False\n",
    "            if date <= date_range2 and date >= date_range1:\n",
    "                date_filterbool=True\n",
    "            if(date_filterbool == False):\n",
    "                continue\n",
    "        \n",
    "        ##### Convert fc2str and word2vec to array, append poster link.\n",
    "        fc2array.append(fc2str.split(' '))\n",
    "        word2vecarray.append(pdfilm_table_from_sqlnew.word2vec[i].split(' '))\n",
    "        posterpathTable.append(path_image_dl +pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2']\\\n",
    "                                                                           == fc2str, 'poster_path'].item())\n",
    "        movie_title_table.append(pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str, 'original_title'].item())\n",
    "        genre_table.append(pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str, 'genres'].item())\n",
    "        prod_countries.append(pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str, 'production_countries_iso_3166_1'].item())\n",
    "\n",
    "    word2vecarray2=list()\n",
    "    fc2array2=list()\n",
    "    posterpathTable2=list()\n",
    "\n",
    "    for i, j in enumerate(word2vecarray):\n",
    "        if(word2vecarray[i][0]!='None'):\n",
    "            word2vecarray2.append(word2vecarray[i])\n",
    "            fc2array2.append(fc2array[i])\n",
    "            posterpath_table2.append(posterpath_table[i])\n",
    "       \n",
    "    ##### Convert fc2array2 and word2vecarray2 to numpy float array \n",
    "    X=np.array(fc2array2)\n",
    "    X=X.astype(np.float)\n",
    "    Y=np.array(word2vecarray2)\n",
    "    Y=Y.astype(np.float)\n",
    "\n",
    "    ##### Reduce number of features from 4096 to 300 for images using T-SVD\n",
    "    RS=9202017\n",
    "    svd = TruncatedSVD(n_components=300, random_state=RS)  ##### algorithm = arpack or randomaized by default\n",
    "    svd.fit(X)  ##### Fit on database fc2 column which contain 4096 features per movie poster\n",
    "    fc2_featuresTSVD=svd.transform(fc2_features) #### reduce user's input image 4096 features to 300\n",
    "    XTSVD=svd.transform(X) #### reduce 4096 features to 300 for each movie poster in the database\n",
    "\n",
    "    ##### Normalization before concatenating, using the standard deviation and mean of features\n",
    "    fc2_featuresTSVD_ravel=fc2_featuresTSVD.ravel()\n",
    "    fc2_featuresTSVD_ravel_norm=(fc2_featuresTSVD_ravel-fc2_featuresTSVD_ravel.mean())/fc2_featuresTSVD_ravel.std()\n",
    "    word2vec_features_norm=(word2vec_features-word2vec_features.mean())/word2vec_features.std()\n",
    "\n",
    "    for i,j in enumerate(XTSVD):\n",
    "        XTSVD[i]=(XTSVD[i]-XTSVD[i].mean())/XTSVD[i].std()\n",
    "        Y[i]=(Y[i]-Y[i].mean())/Y[i].std()\n",
    "    \n",
    "    ##### Concatenation of word2vec and fc2 features\n",
    "    fc2_plus_word2vec=np.concatenate((fc2_featuresTSVD_ravel_norm, word2vec_features_norm), axis=0)\n",
    "    XTSVDPlusY=np.concatenate((XTSVD, Y), axis=1)\n",
    "    \n",
    "    ##### Find the closest neighbors using k-NN algorithm\n",
    "    distance,index = spatial.cKDTree(XTSVDPlusY).query(fc2_plus_word2vec,k=12)\n",
    "\n",
    "    return posterpath_table2, index;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
