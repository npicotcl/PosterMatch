{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function ShowkNN returns the closest neighbors using a k-NN algorithm from 600 concatenated features of image and synopsis.\n",
    "\n",
    "### The image poster features are first reduced to 300 features using a t-SVD algorithm. The features for both image and synopsis are normalized, and then concatenated before using them with a k-NN algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from keras.models import Model\n",
    "from quiver_engine.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from VGG16_PretrainedV1 import VGG16\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "from sqlalchemy import Column, Integer, MetaData, Table\n",
    "\n",
    "import string\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Open and resize Image function \n",
    "\n",
    "def Resize(ImOri):\n",
    "    \n",
    "    img = Image.open(ImOri)\n",
    "    if img.mode == 'L' or img.mode == 'RGBA':\n",
    "            img = img.convert('RGB')\n",
    "    img = img.resize((224, 224), Image.ANTIALIAS)\n",
    "\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    return x;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Function ShowkNN which returns an array of indices corresponding to the nearest neighbor movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Input of ShowkNN function: \n",
    "    - Oview: User's snynopsis input\n",
    "    - ImOri: User's Image input\n",
    "    - Genr: User's genre filter input\n",
    "    - Country: User's country filter input\n",
    "    - DateRange1: User's minimum date\n",
    "    - DateRange1: User's maximum date\n",
    "    '''\n",
    "\n",
    "def ShowkNN(Oview, ImOri, Genr, Country, DateRange1, DateRange2):\n",
    "\n",
    "\n",
    "    Oview=str(Oview)\n",
    "\n",
    "    ImOri=str(ImOri)\n",
    "\n",
    "    Genr=str(Genr)\n",
    "\n",
    "    Country=str(Country)\n",
    "\n",
    "    DateRange1=int(DateRange1)\n",
    "\n",
    "    DateRange2=int(DateRange2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Load VGG16 base model with second to last layer\n",
    "\n",
    "    base_model = VGG16(weights='imagenet')\n",
    "\n",
    "\n",
    "    model2 = Model(input=base_model.input, output=base_model.get_layer('fc2').output)\n",
    "\n",
    "##### Load and resize input image\n",
    "\n",
    "    Resize(ImOri)\n",
    "    \n",
    "\n",
    "\n",
    "##### Get the 4096 features from second to last layer fc2 from input image\n",
    "\n",
    "  \n",
    "\n",
    "    fc2_features = model2.predict(x)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "##### Load Google's pre-trained Word2Vec model.\n",
    "    model1 = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "\n",
    "\n",
    "\n",
    "    vectors=[]\n",
    "\n",
    "\n",
    "    del vectors[:]\n",
    "\n",
    "##### Convert Overview to array of string\n",
    "\n",
    "\n",
    "    sentence = \"%s\" % Oview\n",
    "    sentence = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "\n",
    "\n",
    "\n",
    "##### Remove stop words\n",
    "    sentenceFiltered = [word for word in sentence if word not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "\n",
    "##### Loop over words and get their 300 features each\n",
    "\n",
    "\n",
    "    for w in sentenceFiltered:\n",
    "\n",
    "        try:\n",
    "\n",
    "            vectors.append(model1[w])\n",
    "\n",
    " \n",
    "        except:\n",
    "            continue    \n",
    "\n",
    "##### Average the features over the whole synopsis\n",
    "\n",
    "\n",
    "    MeanVec=[]\n",
    "\n",
    "    del MeanVec[:]\n",
    "\n",
    "    MeanVec=[sum(x)/len(vectors) for x in zip(*vectors)]\n",
    "\n",
    "\n",
    "    word2vec_features = MeanVec\n",
    "\n",
    "\n",
    "##### Convert word2vec_features to numpy array for future concatenation\n",
    "\n",
    "\n",
    "    word2vec_features=np.asarray(word2vec_features)\n",
    "\n",
    "\n",
    "\n",
    "##### Connection to DB and bind the connection to MetaData()   \n",
    "\n",
    "    dbname = 'DBName'\n",
    "    username = 'postgres'\n",
    "\n",
    "\n",
    "\n",
    "    engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "\n",
    "    metadata = MetaData(engine)\n",
    "\n",
    "    metadata.reflect(bind=engine)\n",
    "\n",
    "\n",
    "##### Create pandas df from sql database table #######\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        select_statement = metadata.tables['FilmTable'].select()\n",
    "\n",
    "        pdfilm_table_from_sqlnew = pd.read_sql_query(select_statement,conn)\n",
    "\n",
    "\n",
    "\n",
    "    pathImageDL=\"http://image.tmdb.org/t/p/original/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Create arrays to use for storage\n",
    "\n",
    "    ProdCountries=[]\n",
    "\n",
    "    del ProdCountries[:]\n",
    "\n",
    "\n",
    "    GenreTable=[]\n",
    "\n",
    "    del GenreTable[:]\n",
    "\n",
    "    MovieTitleTable=[]\n",
    "\n",
    "    del MovieTitleTable[:]\n",
    "\n",
    "    posterpathTable=[]\n",
    "\n",
    "    del posterpathTable[:]\n",
    "\n",
    "    fc2array=[]\n",
    "\n",
    "    del fc2array[:]   \n",
    "\n",
    "    increment=0\n",
    "\n",
    "\n",
    "    genresArray=[]\n",
    "\n",
    "    del genresArray[:]\n",
    "    \n",
    "    \n",
    "    word2vecarray=[]\n",
    "\n",
    "    del word2vecarray[:]   \n",
    "    \n",
    "\n",
    "    Date=[]\n",
    "\n",
    "\n",
    "    del Date[:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Loop over fc2 in pandas df\n",
    "    for fc2str in pdfilm_table_from_sqlnew.fc2[(pdfilm_table_from_sqlnew.fc2.str.\\\n",
    "                                                contains(\"None\")) == False]:\n",
    "\n",
    "\n",
    "\n",
    "##### Conditions on genre\n",
    "\n",
    "\n",
    "        genresArray=pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str                                         , 'genres'].item()\n",
    "\n",
    "\n",
    "        if(Genr!=\"All\"):\n",
    "\n",
    "\n",
    "            genreFilter1Bool=False\n",
    "            genreFilter1=Genr\n",
    "\n",
    "\n",
    "            genreFilter2Bool=False\n",
    "\n",
    "\n",
    "            for i in range(0,len(genresArray)):\n",
    "\n",
    "                if genresArray[i] == '%s' % genreFilter1:\n",
    "                    genreFilter1Bool=True\n",
    "\n",
    "\n",
    "\n",
    "            if(genreFilter1Bool == False and genreFilter2Bool==False):\n",
    "                continue\n",
    "                \n",
    "                \n",
    "##### Conditions on country\n",
    "\n",
    "\n",
    "        CountryArray=pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str                                     , 'production_countries_iso_3166_1'].item()\n",
    "\n",
    "        if(Country!=\"All\"):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            CountryFilterBool=False\n",
    "            CountryFilter=Country\n",
    "\n",
    "\n",
    "            for i in range(0,len(CountryArray)):\n",
    "\n",
    "                if CountryArray[i] == '%s' % CountryFilter:\n",
    "                    CountryFilterBool=True\n",
    "\n",
    "            if(CountryFilterBool == False):\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "##### Conditions on date\n",
    "\n",
    "        Date=\"%s\" % pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str                                     , 'release_date'].item()\n",
    "\n",
    "        Date=re.findall(r\"[\\w']+\", Date)\n",
    "\n",
    "        Date=int(Date[0])\n",
    "\n",
    "\n",
    "\n",
    "        if(DateFilter!=\"All\"):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            DateFilterBool=False\n",
    "\n",
    "\n",
    "\n",
    "            if Date <= DateRange2 and Date >= DateRange1:\n",
    "                DateFilterBool=True\n",
    "\n",
    "\n",
    "            if(DateFilterBool == False):\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Convert fc2str and word2vec to array, append poster link.\n",
    "\n",
    "\n",
    "        fc2array.append(fc2str.split(' '))\n",
    "        \n",
    "        word2vecarray.append(pdfilm_table_from_sqlnew.word2vec[i].split(' '))\n",
    "       \n",
    "\n",
    "        posterpathTable.append(pathImageDL +pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2']\\\n",
    "                                                                           == fc2str, 'poster_path'].item())\n",
    "\n",
    "        MovieTitleTable.append(pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str                                                          , 'original_title'].item())\n",
    "        GenreTable.append(pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str                                                          , 'genres'].item())\n",
    "\n",
    "        ProdCountries.append(pdfilm_table_from_sqlnew.loc[pdfilm_table_from_sqlnew['fc2'] == fc2str                                                          , 'production_countries_iso_3166_1'].item())\n",
    "\n",
    "\n",
    "    word2vecarray2=[]\n",
    "\n",
    "    fc2array2=[]\n",
    "    \n",
    "    posterpathTable2=[]\n",
    "    \n",
    "    del posterpathTable2[:]\n",
    "\n",
    "    del word2vecarray2[:]\n",
    "    \n",
    "    del fc2array2[:]\n",
    "\n",
    "\n",
    "    for i, j in enumerate(word2vecarray):\n",
    "        if(word2vecarray[i][0]!='None'):\n",
    "            word2vecarray2.append(word2vecarray[i])\n",
    "            fc2array2.append(fc2array[i])\n",
    "            posterpathTable2.append(posterpathTable[i])\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "##### Convert fc2array2 and word2vecarray2 to numpy float array \n",
    "\n",
    "\n",
    "    X=np.array(fc2array2)\n",
    "\n",
    "\n",
    "    X=X.astype(np.float)\n",
    "\n",
    "\n",
    "    Y=np.array(word2vecarray2)\n",
    "    \n",
    "\n",
    "    Y=Y.astype(np.float)\n",
    "    \n",
    "\n",
    "##### Reduce number of features from 4096 to 300 for images using T-SVD\n",
    "\n",
    "\n",
    "\n",
    "    RS=9202017\n",
    "\n",
    "    svd = TruncatedSVD(n_components=300, random_state=RS)  ##### algorithm = arpack or randomaized by default\n",
    "\n",
    "    svd.fit(X)  ##### Fit on database fc2 column which contain 4096 features per movie poster\n",
    "\n",
    "    fc2_featuresTSVD=svd.transform(fc2_features) #### reduce user's input image 4096 features to 300\n",
    "\n",
    "    XTSVD=svd.transform(X) #### reduce 4096 features to 300 for each movie poster in the database\n",
    "\n",
    "    \n",
    "    \n",
    "##### Normalization before concatenating, using the standard deviation and mean of features\n",
    "    \n",
    "    fc2_featuresTSVDravel=fc2_featuresTSVD.ravel()\n",
    "\n",
    "    \n",
    "    fc2_featuresTSVDravelNorm=(fc2_featuresTSVDravel-fc2_featuresTSVDravel.mean())/fc2_featuresTSVDravel.std()\n",
    "\n",
    "    word2vec_featuresNorm=(word2vec_features-word2vec_features.mean())/word2vec_features.std()\n",
    "\n",
    "    \n",
    "    \n",
    "    for i,j in enumerate(XTSVD):\n",
    "        XTSVD[i]=(XTSVD[i]-XTSVD[i].mean())/XTSVD[i].std()\n",
    "        Y[i]=(Y[i]-Y[i].mean())/Y[i].std()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "##### Concatenation of word2vec and fc2 features\n",
    "\n",
    "    fc2PlusWord2Vec=np.concatenate((fc2_featuresTSVDravelNorm, word2vec_featuresNorm), axis=0)\n",
    "\n",
    "\n",
    "    XTSVDPlusY=np.concatenate((XTSVD, Y), axis=1)\n",
    "    \n",
    "##### Find the closest neighbors using k-NN algorithm\n",
    "\n",
    "\n",
    "    distance,index = spatial.cKDTree(XTSVDPlusY).query(fc2PlusWord2Vec,k=12)\n",
    "\n",
    "\n",
    "\n",
    "    return posterpathTable2, index;\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
